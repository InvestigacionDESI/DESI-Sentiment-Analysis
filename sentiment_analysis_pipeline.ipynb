{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed73612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\gerar\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\gerar\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gerar\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\gerar\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gerar\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\gerar\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 165.2 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.0 kB 187.9 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.0 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 295.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gerar\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.5 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------------------------------- 0.2/15.5 MB 2.1 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.3/15.5 MB 2.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/15.5 MB 2.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.7/15.5 MB 3.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.0/15.5 MB 3.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.3/15.5 MB 4.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/15.5 MB 4.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.9/15.5 MB 4.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.2/15.5 MB 4.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.6/15.5 MB 5.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.9/15.5 MB 5.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.3/15.5 MB 5.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.7/15.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.0/15.5 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.5/15.5 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.9/15.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.3/15.5 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.8/15.5 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.4/15.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.7/15.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.2/15.5 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.7/15.5 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.3/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.5/15.5 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.0/15.5 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.5/15.5 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.0/15.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.5 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.6/15.5 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.5 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 11.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If necessary, install the required libraries\n",
    "%pip install pandas nltk scikit-learn openpyxl matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcd56e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gerar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gerar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gerar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK data files (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad36c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been combined successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine Multiple Excel Files\n",
    "directory = \"./datasets\"  # Replace with the path to your Excel files\n",
    "\n",
    "# Create an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read each Excel file and append it to the list\n",
    "        df = pd.read_excel(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Export the combined dataframe to a new Excel file\n",
    "combined_df.to_excel(\"combined_tweets.xlsx\", index=False)\n",
    "print(\"All files have been combined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eeda78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bookmarkCount       conversationId                       createdAt  \\\n",
      "0               0  1843054927339483464  Sun Oct 06 22:25:11 +0000 2024   \n",
      "1               0  1843053407990698186  Sun Oct 06 22:19:09 +0000 2024   \n",
      "2               0  1843026753016807813  Sun Oct 06 20:50:37 +0000 2024   \n",
      "3               0  1842995428897538332  Sun Oct 06 18:28:46 +0000 2024   \n",
      "4               1  1842988481137492342  Sun Oct 06 18:01:09 +0000 2024   \n",
      "5               0  1842988313897992279  Sun Oct 06 18:00:29 +0000 2024   \n",
      "6               0  1842221123095998617  Sun Oct 06 17:46:19 +0000 2024   \n",
      "7               0  1842862145056219265  Sun Oct 06 15:53:20 +0000 2024   \n",
      "8               0  1842938219169542144  Sun Oct 06 15:52:04 +0000 2024   \n",
      "9               0  1842938219169542144  Sun Oct 06 15:26:35 +0000 2024   \n",
      "10              0  1843091498751217932  Mon Oct 07 11:07:37 +0000 2024   \n",
      "11              0  1842957845945593936  Mon Oct 07 11:00:09 +0000 2024   \n",
      "12              0  1843234305428144414  Mon Oct 07 10:17:58 +0000 2024   \n",
      "13              0  1843154364099154244  Mon Oct 07 06:54:54 +0000 2024   \n",
      "14              0  1843182040793141623  Mon Oct 07 06:50:17 +0000 2024   \n",
      "15              0  1842922002405118356  Mon Oct 07 06:38:08 +0000 2024   \n",
      "16              0  1843150274061586868  Mon Oct 07 04:44:04 +0000 2024   \n",
      "17              0  1843139230291382757  Mon Oct 07 04:00:11 +0000 2024   \n",
      "18              0  1843106260578918674  Mon Oct 07 03:13:17 +0000 2024   \n",
      "19              0  1843117690740978051  Mon Oct 07 02:34:35 +0000 2024   \n",
      "20              0  1842708701993664576  Sat Oct 05 23:29:25 +0000 2024   \n",
      "21              0  1842655765938733155  Sat Oct 05 23:18:56 +0000 2024   \n",
      "22              1  1842676534777176419  Sat Oct 05 21:21:35 +0000 2024   \n",
      "23              0  1842668843673825360  Sat Oct 05 20:51:02 +0000 2024   \n",
      "24              0  1842667929567101091  Sat Oct 05 20:47:26 +0000 2024   \n",
      "25              0  1842660381589639547  Sat Oct 05 20:35:37 +0000 2024   \n",
      "26              0  1842656623086510119  Sat Oct 05 20:07:32 +0000 2024   \n",
      "27              1  1842238476873506997  Sat Oct 05 19:59:25 +0000 2024   \n",
      "28              0  1842283467201298501  Sat Oct 05 19:13:00 +0000 2024   \n",
      "29              0  1842573577343602952  Sat Oct 05 18:39:02 +0000 2024   \n",
      "\n",
      "                     id inReplyToUsername  isConversationControlled  isPinned  \\\n",
      "0   1843054927339483464               NaN                     False     False   \n",
      "1   1843053407990698186               NaN                     False     False   \n",
      "2   1843031128908702146            ixuatl                     False     False   \n",
      "3   1842995428897538332               NaN                     False     False   \n",
      "4   1842988481137492342               NaN                     False     False   \n",
      "5   1842988313897992279               NaN                     False     False   \n",
      "6   1842984745657135609        fleurinnna                     False     False   \n",
      "7   1842956312881328277    IsraelVive1948                     False     False   \n",
      "8   1842955993887777177    EnriqueReinaHN                     False     False   \n",
      "9   1842949584567628144    EnriqueReinaHN                     False     False   \n",
      "10  1843246798032539865     InformaCosmos                     False     False   \n",
      "11  1843244919923896416   Antonio27591643                     False     False   \n",
      "12  1843234305428144414               NaN                     False     False   \n",
      "13  1843183199977144442      GildoGarzaMx                     False     False   \n",
      "14  1843182040793141623               NaN                     False     False   \n",
      "15  1843178983409811575         jrsestaca                     False     False   \n",
      "16  1843150274061586868               NaN                     False     False   \n",
      "17  1843139230291382757               NaN                     False     False   \n",
      "18  1843127430648877146       candrews_cl                     False     False   \n",
      "19  1843117690740978051               NaN                     False     False   \n",
      "20  1842708701993664576               NaN                     False     False   \n",
      "21  1842706067446272408   GuacamayanLeaks                     False     False   \n",
      "22  1842676534777176419               NaN                     False     False   \n",
      "23  1842668843673825360               NaN                     False     False   \n",
      "24  1842667937980932541         XoloElvis                     False     False   \n",
      "25  1842664967084118269      JeckovKanani                     False     False   \n",
      "26  1842657899400601947      CoyunturaNic                     False     False   \n",
      "27  1842655855751368997           eduuxqs                     False     False   \n",
      "28  1842644173574275072      Claudiashein                     False     False   \n",
      "29  1842635625737928981   Carloslopezjone                     False     False   \n",
      "\n",
      "    isQuote  isReply  isRetweet  ... quoteCount       quoteId replyCount  \\\n",
      "0      True    False      False  ...          0  1.843041e+18          0   \n",
      "1      True    False      False  ...          0  1.843041e+18          0   \n",
      "2     False     True      False  ...          0           NaN          1   \n",
      "3     False    False      False  ...          0           NaN          0   \n",
      "4     False    False      False  ...          1           NaN          0   \n",
      "5     False    False      False  ...          0           NaN          0   \n",
      "6     False     True      False  ...          0           NaN          1   \n",
      "7     False     True      False  ...          0           NaN          0   \n",
      "8     False     True      False  ...          0           NaN          0   \n",
      "9     False     True      False  ...          0           NaN          1   \n",
      "10    False     True      False  ...          0           NaN          0   \n",
      "11    False     True      False  ...          0           NaN          0   \n",
      "12    False    False      False  ...          0           NaN          0   \n",
      "13    False     True      False  ...          0           NaN          1   \n",
      "14    False    False      False  ...          0           NaN          0   \n",
      "15    False     True      False  ...          0           NaN          0   \n",
      "16    False    False      False  ...          0           NaN          1   \n",
      "17    False    False      False  ...          0           NaN          0   \n",
      "18    False     True      False  ...          0           NaN          0   \n",
      "19    False    False      False  ...          0           NaN          0   \n",
      "20    False    False      False  ...          0           NaN          0   \n",
      "21    False     True      False  ...          0           NaN          1   \n",
      "22    False    False      False  ...          0           NaN          0   \n",
      "23    False    False      False  ...          0           NaN          1   \n",
      "24    False     True      False  ...          0           NaN          1   \n",
      "25    False     True      False  ...          0           NaN          2   \n",
      "26    False     True      False  ...          0           NaN          1   \n",
      "27    False     True      False  ...          0           NaN          2   \n",
      "28    False     True      False  ...          0           NaN          0   \n",
      "29    False     True      False  ...          0           NaN          0   \n",
      "\n",
      "   retweetCount               source  \\\n",
      "0             0   Twitter for iPhone   \n",
      "1             0  Twitter for Android   \n",
      "2             0  Twitter for Android   \n",
      "3             0    TweetDeck Web App   \n",
      "4             2       Hootsuite Inc.   \n",
      "5             4            Publer.io   \n",
      "6             0   Twitter for iPhone   \n",
      "7             0   Twitter for iPhone   \n",
      "8             0  Twitter for Android   \n",
      "9             0  Twitter for Android   \n",
      "10            0   Twitter for iPhone   \n",
      "11            0   Twitter for iPhone   \n",
      "12            0   Twitter for iPhone   \n",
      "13            0  Twitter for Android   \n",
      "14            0      Twitter Web App   \n",
      "15            0  Twitter for Android   \n",
      "16            0   Twitter for iPhone   \n",
      "17            0              dlvr.it   \n",
      "18            0   Twitter for iPhone   \n",
      "19            0              dlvr.it   \n",
      "20            0   Twitter for iPhone   \n",
      "21            0  Twitter for Android   \n",
      "22            2      EL PAÍS Echobox   \n",
      "23            0      Twitter Web App   \n",
      "24            1    TweetDeck Web App   \n",
      "25            0      Twitter Web App   \n",
      "26            2      Twitter Web App   \n",
      "27            0   Twitter for iPhone   \n",
      "28            0   Twitter for iPhone   \n",
      "29            0   Twitter for iPhone   \n",
      "\n",
      "                                                 text  \\\n",
      "0   México es un riesgo para los Colombianos, si n...   \n",
      "1   Visitar México se ha convertido en pesadilla p...   \n",
      "2   Hablemos ahora del problema de la migración. M...   \n",
      "3   El muro entre EEUU y México impide la migració...   \n",
      "4   #Video Idles, su rock hace temblar al Pepsi Ce...   \n",
      "5    #LoMejorDeLaSemana #LaEncrucijada\\n\\n➡️ Migra...   \n",
      "6   @fleurinnna @Drselosdije @DeniseMeadeG Se ve q...   \n",
      "7   @IsraelVive1948 MEXICO \\nFRANCIA DEBE PREOCUPA...   \n",
      "8   @EnriqueReinaHN Probablemente indique que más ...   \n",
      "9   @EnriqueReinaHN Ese es un dato que no es concl...   \n",
      "10  @InformaCosmos La migración ilegal. Es un grav...   \n",
      "11  @Antonio27591643 Y este de que habla. Mejor qu...   \n",
      "12  Estamos subestimando la migración irregular en...   \n",
      "13  @GildoGarzaMx @EvelynSalgadoP @Claudiashein Es...   \n",
      "14  Admite Sheinbaum estrategia de repatriación pa...   \n",
      "15  @jrsestaca Durante el primer año de Biden, los...   \n",
      "16  Vengo de hacer migración en México  y acabo de...   \n",
      "17  Andrew Selee llama a líderes políticos a acept...   \n",
      "18  @candrews_cl @joseantoniokast Insistir en que ...   \n",
      "19  La migración puede ser una oportunidad para el...   \n",
      "20  Felicidades a @ClaraBrugadaM en su nuevo rol d...   \n",
      "21  @GuacamayanLeaks Trabajos mejor remunerados y ...   \n",
      "22  Su creadora, Karla Reyes, latina e hija de mig...   \n",
      "23  INVITACIÓN DIPLOMADO ECONOMÍA Y HUMANISMO: MIG...   \n",
      "24  Quien va a ir al conflicto armado?= Pues la cl...   \n",
      "25  @JeckovKanani El tren de aragua ya esta en mex...   \n",
      "26   #migración | La frontera sur entre Estados Un...   \n",
      "27  @eduuxqs Prefiero mil veces vivir en México a ...   \n",
      "28  @Claudiashein Y no abordaron el narcotrafico ?...   \n",
      "29  @Carloslopezjone Por la migración a la inversa...   \n",
      "\n",
      "                                           twitterUrl   type  \\\n",
      "0   https://twitter.com/DalilahAmell/status/184305...  tweet   \n",
      "1   https://twitter.com/SaraJimnez14446/status/184...  tweet   \n",
      "2   https://twitter.com/ixuatl/status/184303112890...  tweet   \n",
      "3   https://twitter.com/Julestelles/status/1842995...  tweet   \n",
      "4   https://twitter.com/proceso/status/18429884811...  tweet   \n",
      "5   https://twitter.com/RompevientoTV/status/18429...  tweet   \n",
      "6   https://twitter.com/Alphons78537503/status/184...  tweet   \n",
      "7   https://twitter.com/jaime_barajas7/status/1842...  tweet   \n",
      "8   https://twitter.com/LizzmendezP/status/1842955...  tweet   \n",
      "9   https://twitter.com/marcoscl1983/status/184294...  tweet   \n",
      "10  https://twitter.com/Anty99823772/status/184324...  tweet   \n",
      "11  https://twitter.com/capilibertad/status/184324...  tweet   \n",
      "12  https://twitter.com/CafecitoConTata/status/184...  tweet   \n",
      "13  https://twitter.com/AguilaRealPue/status/18431...  tweet   \n",
      "14  https://twitter.com/r24edomex/status/184318204...  tweet   \n",
      "15  https://twitter.com/cuxk/status/18431789834098...  tweet   \n",
      "16  https://twitter.com/Combo_Ex/status/1843150274...  tweet   \n",
      "17  https://twitter.com/infobaemexico/status/18431...  tweet   \n",
      "18  https://twitter.com/AAutodidacta/status/184312...  tweet   \n",
      "19  https://twitter.com/infobaemexico/status/18431...  tweet   \n",
      "20  https://twitter.com/DanaGraberLadek/status/184...  tweet   \n",
      "21  https://twitter.com/ceobricks/status/184270606...  tweet   \n",
      "22  https://twitter.com/elpaismexico/status/184267...  tweet   \n",
      "23  https://twitter.com/Sombrayarenar/status/18426...  tweet   \n",
      "24  https://twitter.com/XoloElvis/status/184266793...  tweet   \n",
      "25  https://twitter.com/chords_secret/status/18426...  tweet   \n",
      "26  https://twitter.com/CoyunturaNic/status/184265...  tweet   \n",
      "27  https://twitter.com/luiscepeda33/status/184265...  tweet   \n",
      "28  https://twitter.com/AguilaAZC/status/184264417...  tweet   \n",
      "29  https://twitter.com/CostingWorld_II/status/184...  tweet   \n",
      "\n",
      "                                                  url  viewCount  \n",
      "0   https://x.com/DalilahAmell/status/184305492733...         69  \n",
      "1   https://x.com/SaraJimnez14446/status/184305340...         21  \n",
      "2     https://x.com/ixuatl/status/1843031128908702146         41  \n",
      "3   https://x.com/Julestelles/status/1842995428897...          7  \n",
      "4    https://x.com/proceso/status/1842988481137492342       6870  \n",
      "5   https://x.com/RompevientoTV/status/18429883138...        288  \n",
      "6   https://x.com/Alphons78537503/status/184298474...         15  \n",
      "7   https://x.com/jaime_barajas7/status/1842956312...         13  \n",
      "8   https://x.com/LizzmendezP/status/1842955993887...         79  \n",
      "9   https://x.com/marcoscl1983/status/184294958456...        217  \n",
      "10  https://x.com/Anty99823772/status/184324679803...          6  \n",
      "11  https://x.com/capilibertad/status/184324491992...          3  \n",
      "12  https://x.com/CafecitoConTata/status/184323430...        119  \n",
      "13  https://x.com/AguilaRealPue/status/18431831999...        213  \n",
      "14  https://x.com/r24edomex/status/184318204079314...          3  \n",
      "15      https://x.com/cuxk/status/1843178983409811575          6  \n",
      "16  https://x.com/Combo_Ex/status/1843150274061586868        317  \n",
      "17  https://x.com/infobaemexico/status/18431392302...        108  \n",
      "18  https://x.com/AAutodidacta/status/184312743064...         29  \n",
      "19  https://x.com/infobaemexico/status/18431176907...        113  \n",
      "20  https://x.com/DanaGraberLadek/status/184270870...        121  \n",
      "21  https://x.com/ceobricks/status/184270606744627...        130  \n",
      "22  https://x.com/elpaismexico/status/184267653477...        673  \n",
      "23  https://x.com/Sombrayarenar/status/18426688436...        128  \n",
      "24  https://x.com/XoloElvis/status/184266793798093...        224  \n",
      "25  https://x.com/chords_secret/status/18426649670...         88  \n",
      "26  https://x.com/CoyunturaNic/status/184265789940...        108  \n",
      "27  https://x.com/luiscepeda33/status/184265585575...       1411  \n",
      "28  https://x.com/AguilaAZC/status/184264417357427...         17  \n",
      "29  https://x.com/CostingWorld_II/status/184263562...         23  \n",
      "\n",
      "[30 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9def157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Complete!\n"
     ]
    }
   ],
   "source": [
    "# Load the combined Excel file\n",
    "df = pd.read_excel(\"combined_tweets.xlsx\")\n",
    "\n",
    "# Data Cleaning Function - Remove URLs, special characters, and usernames\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions (@username)\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Clean the text data\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)  # Replace 'tweet_text' with your column name\n",
    "\n",
    "# Tokenization\n",
    "df['tokens'] = df['cleaned_text'].apply(word_tokenize)\n",
    "\n",
    "# Removing Stopwords\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Join tokens back into a single string\n",
    "df['final_text'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features\n",
    "X = vectorizer.fit_transform(df['final_text'])\n",
    "\n",
    "# Encode Sentiment Labels (if applicable)\n",
    "if 'sentiment' in df.columns:\n",
    "    df['sentiment_label'] = df['sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})\n",
    "    y = df['sentiment_label']\n",
    "else:\n",
    "    y = None\n",
    "\n",
    "# Save preprocessed data to Excel\n",
    "processed_df = df[['final_text', 'sentiment_label']] if y is not None else df[['final_text']]\n",
    "processed_df.to_excel(\"preprocessed_tweets.xlsx\", index=False)\n",
    "print(\"Data Preprocessing Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45fd49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
